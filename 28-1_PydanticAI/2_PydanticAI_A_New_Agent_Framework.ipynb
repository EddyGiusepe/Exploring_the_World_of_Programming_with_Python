{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w66Ao3_gPTa3"
      },
      "source": [
        "<p align = \"center\" draggable=”false” ><img src=\"https://github.com/AI-Maker-Space/LLM-Dev-101/assets/37101144/d1343317-fa2f-41e1-8af1-1dbb18399719\"\n",
        "     width=\"200px\"\n",
        "     height=\"auto\"/>\n",
        "</p>\n",
        "\n",
        "<h1 align=\"center\" id=\"heading\">AI Makerspace: Pydantic AI Event</h1>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Sou o <font color=\"pink\">Senior Data Scientist.: Dr. Eddy Giusepe Chirinos Isidro</font> e aqui estudarei a Pydantic AI.\n",
        "\n",
        "\n",
        "Links de estudo:\n",
        "\n",
        "* [logfire](https://logfire.pydantic.dev/eddygiusepe/teste-ai-makerspace/settings/setup)\n",
        "* [Anthropic](https://console.anthropic.com/settings/keys)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Neste evento apresentado por ``AI Makerspace``, construiremos um gerador de piadas usando a estrutura de IA do Pydantic!\n",
        "\n",
        "A estrutura de IA do ``Pydantic`` é uma nova maneira de criar agentes com base nos trabalhos anteriores do ``Pydantic`` sobre validação de dados e modelos de dados.\n",
        "\n",
        "Começaremos com nossas dependências:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6tJXXr3X7jq9",
        "outputId": "886fe466-ea12-4b4a-b7fb-5ee12efeee19"
      },
      "outputs": [],
      "source": [
        "#!pip install -qU pydantic-ai logfire devtools"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eR7EHUoSPTa4"
      },
      "source": [
        "Precisaremos de algumas chaves de API para este exemplo:\n",
        "\n",
        "Vamos aproveitar o novo agente \"melhor vibração\" para determinar se as piadas são hilárias - e o ``Claude 3.7 Sonnet`` para gerar algumas piadas iniciais."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O6Fx09gV-Hbw",
        "outputId": "2e01273d-8171-43fa-970d-29618bb8d709"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from dotenv import load_dotenv, find_dotenv\n",
        "_ = load_dotenv(find_dotenv()) # read local .env file\n",
        "#openai.api_key  = os.environ['OPENAI_API_KEY']\n",
        "Eddy_key_openai  = os.environ['OPENAI_API_KEY']\n",
        "Eddy_key_anthropic = os.environ['ANTHROPIC_API_KEY']\n",
        "Eddy_key_logfire = os.environ['LOGFIRE_API_KEY']\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yuCi8drrPTa5"
      },
      "source": [
        "Como estamos no notebook, precisaremos aninhar o asyncio para executar nosso código."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "UsGFUXAF-2m7"
      },
      "outputs": [],
      "source": [
        "import nest_asyncio\n",
        "nest_asyncio.apply()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MOS8Hc3iPTa5"
      },
      "source": [
        "GRANDE PAREDE DE DECLARAÇÕES DE IMPORTAÇÃO!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "yV7QNACmBSG_"
      },
      "outputs": [],
      "source": [
        "from __future__ import annotations as _annotations\n",
        "\n",
        "from dataclasses import dataclass, field\n",
        "from pathlib import Path\n",
        "from typing import Annotated\n",
        "\n",
        "import logfire\n",
        "from devtools import debug\n",
        "from pydantic_graph import BaseNode, Edge, End, Graph, GraphRunContext, HistoryStep\n",
        "\n",
        "from pydantic_ai import Agent\n",
        "from pydantic_ai.format_as_xml import format_as_xml\n",
        "from pydantic_ai.messages import ModelMessage"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Z1D11hCPTa5"
      },
      "source": [
        "Vamos usar o Logfire para rastrear nossos eventos!\n",
        "\n",
        "Você pode se inscrever em uma conta gratuita em https://pydantic.dev/logfire!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W5k00s3rB6q6",
        "outputId": "96e08417-1b5b-4dc2-dffc-ffb987dd3b68"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<logfire._internal.main.Logfire at 0x7f080fa02a50>"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[1mLogfire\u001b[0m project URL: \n",
            "\u001b]8;id=808514;https://logfire.pydantic.dev/eddygiusepe/teste-ai-makerspace\u001b\\\u001b[4;36mhttps://logfire.pydantic.dev/eddygiusepe/teste-ai-makerspace\u001b[0m\u001b]8;;\u001b\\\n"
          ]
        }
      ],
      "source": [
        "logfire.configure(token=os.environ[\"LOGFIRE_API_KEY\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ENHrg3oGPTa5"
      },
      "source": [
        "## Building our Agents!\n",
        "\n",
        "Para construir um gerador de piadas multi-agente, precisaremos construir um par de agentes.\n",
        "\n",
        "Vamos começar com nosso agente \"Joke Generator\".\n",
        "\n",
        "> NOTE: O ``\"instrument=True\"`` é importante aqui. Isso permitirá que rastreemos os eventos no Logfire."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "x1cmzSdiCAem"
      },
      "outputs": [],
      "source": [
        "joke_generator_agent = Agent(\n",
        "    \"anthropic:claude-3-7-sonnet-latest\",\n",
        "    result_type=str,\n",
        "    instrument=True\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Pu_wr6sPTa5"
      },
      "source": [
        "Então, similar a outros frameworks de agentes, queremos definir nosso estado.\n",
        "\n",
        "> ``NOTE:`` Limitaremos a 5 tentativas para gerar uma piada, apenas no caso de Claude estar tendo um dia ruim."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "p2L3SMffCMJl"
      },
      "outputs": [],
      "source": [
        "@dataclass\n",
        "class JokeState:\n",
        "    joke: str | None = None\n",
        "    joke_generator_agent_messages: list[ModelMessage] = field(default_factory=list)\n",
        "    evaluate_agent_messages: list[ModelMessage] = field(default_factory=list)\n",
        "    attempts: int = 0\n",
        "    max_attempts: int = 5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H46YpQEfPTa6"
      },
      "source": [
        "Em seguida, vamos configurar nosso agente ``\"Joke Generator\"``, que será responsável por gerar piadas e incorporar feedback na geração de piadas.\n",
        "\n",
        "Nosso ``JokeGenerator`` tomará nosso ``BaseNode`` com nosso ``JokeState``, e retornará um ``Evaluate`` node.\n",
        "\n",
        "Este é o caminho que podemos produzir nosso gráfico! Podemos encadear nossos nós para produzir um gráfico - incluindo, como veremos, lógica condicional - assim como em ``LangGraph``!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "sbsM-OolCPZs"
      },
      "outputs": [],
      "source": [
        "@dataclass\n",
        "class JokeGenerator(BaseNode[JokeState]):\n",
        "    feedback: str | None = None\n",
        "\n",
        "    async def run(self, ctx: GraphRunContext[JokeState]) -> Evaluate:\n",
        "        ctx.state.attempts += 1\n",
        "\n",
        "        prompt = 'Invente uma piada sobre gatos. Ela deve ser engraçada e interessante.'\n",
        "\n",
        "        if self.feedback:\n",
        "            prompt = f\"\"\"Invente uma piada sobre gatos. Ela deve ser engraçada e interessante.\n",
        "\n",
        "Tentativa anterior: {ctx.state.joke}\n",
        "\n",
        "Feedback na tentativa anterior: {self.feedback}\n",
        "\n",
        "Por favor, crie uma nova piada que aborde este feedback.\"\"\"\n",
        "\n",
        "        result = await joke_generator_agent.run(\n",
        "            prompt,\n",
        "            message_history=ctx.state.joke_generator_agent_messages,\n",
        "        )\n",
        "        ctx.state.joke_generator_agent_messages += result.all_messages()\n",
        "        ctx.state.joke = result.data\n",
        "\n",
        "        return Evaluate()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-1cv418VPTa6"
      },
      "source": [
        "Em seguida, podemos produzir outro nó que será responsável por iniciar nosso processo de avaliação."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "wAwjq2W1CRAc"
      },
      "outputs": [],
      "source": [
        "@dataclass\n",
        "class ProducedJoke(BaseNode[JokeState]):\n",
        "    joke: str | None = None\n",
        "\n",
        "    async def run(self, ctx: GraphRunContext[JokeState]) -> Evaluate:\n",
        "        assert self.joke is not None\n",
        "        return Evaluate(self.joke)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5no8z5wZPTa6"
      },
      "source": [
        "Precisaremos criar algum estado de avaliação, que ajudará o LLM a determinar como responder."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "fSUtLjMUCTHO"
      },
      "outputs": [],
      "source": [
        "@dataclass\n",
        "class EvaluationResult:\n",
        "    dope: bool\n",
        "    funny: bool\n",
        "    comment: str"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Irkt7E1XPTa6"
      },
      "source": [
        "Nosso agente de avaliação será um modelo ``GPT-4.5 preview``, que será responsável por avaliar a piada. Estamos usando este modelo porque, embora não seja ótimo para raciocínio, é ótimo para ser engraçado!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "PPIc3VKSCVJK"
      },
      "outputs": [],
      "source": [
        "evaluate_agent = Agent(\n",
        "    'openai:gpt-4.5-preview',\n",
        "    result_type=EvaluationResult,\n",
        "    system_prompt='Dado uma piada, avalie se a piada é engraçada ou não - também avalie se a piada é engraçada. Ela precisa ser *muito* boa. Sugira melhorias na piada se não for.',\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IJfhIP3DPTa6"
      },
      "source": [
        "Agora vamos criar nosso ``Evaluate`` node.\n",
        "\n",
        "Observe como estamos retornando um ``Congratulate`` ou ``Reprimand`` node, dependendo da avaliação - isso é como adicionamos complexidade ao nosso gráfico."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "0ZkG-GuqC1oF"
      },
      "outputs": [],
      "source": [
        "@dataclass\n",
        "class Evaluate(BaseNode[JokeState]):\n",
        "    async def run(\n",
        "        self,\n",
        "        ctx: GraphRunContext[JokeState],\n",
        "    ) -> Congratulate | Reprimand | End:\n",
        "        assert ctx.state.joke is not None\n",
        "\n",
        "        result = await evaluate_agent.run(\n",
        "            format_as_xml({'joke': ctx.state.joke}),\n",
        "            message_history=ctx.state.evaluate_agent_messages,\n",
        "        )\n",
        "        ctx.state.evaluate_agent_messages += result.all_messages()\n",
        "\n",
        "        if ctx.state.attempts >= ctx.state.max_attempts:\n",
        "            print(f\"Reached maximum attempts ({ctx.state.max_attempts}). Best joke so far: {ctx.state.joke}\")\n",
        "            print(f\"Final feedback: {result.data.comment}\")\n",
        "            return End(None)\n",
        "\n",
        "        if result.data.funny and result.data.dope:\n",
        "            return Congratulate(result.data.comment)\n",
        "        else:\n",
        "            return Reprimand(result.data.comment)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qYwjMsjxPTa6"
      },
      "source": [
        "Em seguida, vamos criar nosso ``Congratulate`` e ``Reprimand`` nodes.\n",
        "\n",
        "Estes são nossos estados de ``\"sucesso\"`` e ``\"falha\"`` - eles serão usados para determinar o próximo nó em nosso gráfico.\n",
        "\n",
        "`End` se a piada for boa."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "XcJ5fzdDC3_-"
      },
      "outputs": [],
      "source": [
        "@dataclass\n",
        "class Congratulate(BaseNode[JokeState, None, None]):\n",
        "    comment: str\n",
        "\n",
        "    async def run(\n",
        "        self, ctx: GraphRunContext[JokeState]\n",
        "    ) -> Annotated[End, Edge(label='success')]:\n",
        "        print(f'Encontrei uma piada engraçada e interessante após {ctx.state.attempts} tentativas!')\n",
        "        print(f'Piada: {ctx.state.joke}')\n",
        "        print(f'Feedback: {self.comment}')\n",
        "        return End(None)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GPghk0ZAPTa6"
      },
      "source": [
        "`Reprimand` se a piada precisa de melhorias."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "Utvgro03C6p_"
      },
      "outputs": [],
      "source": [
        "@dataclass\n",
        "class Reprimand(BaseNode[JokeState]):\n",
        "    comment: str\n",
        "\n",
        "    async def run(self, ctx: GraphRunContext[JokeState]) -> JokeGenerator:\n",
        "        print(f'Tentativa {ctx.state.attempts}: {ctx.state.joke}')\n",
        "        print(f'Feedback: {self.comment}')\n",
        "        return JokeGenerator(feedback=self.comment)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "884L6WvLPTa6"
      },
      "source": [
        "Por fim, vamos criar nosso gráfico!\n",
        "\n",
        "Observe que podemos apenas colocar os nós, conforme definimos suas conexões em cada nó."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "42ZbEFq7C-lz"
      },
      "outputs": [],
      "source": [
        "question_graph = Graph(\n",
        "    nodes=(JokeGenerator, Evaluate, Congratulate, Reprimand), state_type=JokeState\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        },
        "id": "zrEH5XYMdLiR",
        "outputId": "f4dc6ca3-7c6e-4e92-ac2c-a8037d8ca3ae"
      },
      "outputs": [
        {
          "data": {
            "image/jpeg": "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",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from IPython.display import Image, display\n",
        "\n",
        "display(Image(question_graph.mermaid_image(start_node=JokeGenerator)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BzG5KBq6PTa6"
      },
      "source": [
        "Por fim, podemos executar nosso gráfico - é tão fácil quanto executar o próximo nó em um loop até que atinjamos o nó ``End``!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jKx-uwvdDCFq",
        "outputId": "fe827a18-1336-4461-bfb4-7ddac60c14af"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "03:17:09.845 run automated joke generator\n",
            "03:17:09.887   run node JokeGenerator\n",
            "03:17:09.888     joke_generator_agent run\n",
            "03:17:09.889       preparing model request params\n",
            "03:17:09.889       chat claude-3-7-sonnet-latest\n"
          ]
        },
        {
          "ename": "ModelHTTPError",
          "evalue": "status_code: 400, model_name: claude-3-7-sonnet-latest, body: {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'Your credit balance is too low to access the Anthropic API. Please go to Plans & Billing to upgrade or purchase credits.'}}",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mBadRequestError\u001b[39m                           Traceback (most recent call last)",
            "\u001b[36mFile \u001b[39m\u001b[32m~/1_github/Exploring_the_World_of_Programming_with_Python/.venv/lib/python3.13/site-packages/pydantic_ai/models/anthropic.py:235\u001b[39m, in \u001b[36mAnthropicModel._messages_create\u001b[39m\u001b[34m(self, messages, stream, model_settings, model_request_parameters)\u001b[39m\n\u001b[32m    234\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m235\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.client.messages.create(\n\u001b[32m    236\u001b[39m         max_tokens=model_settings.get(\u001b[33m'\u001b[39m\u001b[33mmax_tokens\u001b[39m\u001b[33m'\u001b[39m, \u001b[32m1024\u001b[39m),\n\u001b[32m    237\u001b[39m         system=system_prompt \u001b[38;5;129;01mor\u001b[39;00m NOT_GIVEN,\n\u001b[32m    238\u001b[39m         messages=anthropic_messages,\n\u001b[32m    239\u001b[39m         model=\u001b[38;5;28mself\u001b[39m._model_name,\n\u001b[32m    240\u001b[39m         tools=tools \u001b[38;5;129;01mor\u001b[39;00m NOT_GIVEN,\n\u001b[32m    241\u001b[39m         tool_choice=tool_choice \u001b[38;5;129;01mor\u001b[39;00m NOT_GIVEN,\n\u001b[32m    242\u001b[39m         stream=stream,\n\u001b[32m    243\u001b[39m         temperature=model_settings.get(\u001b[33m'\u001b[39m\u001b[33mtemperature\u001b[39m\u001b[33m'\u001b[39m, NOT_GIVEN),\n\u001b[32m    244\u001b[39m         top_p=model_settings.get(\u001b[33m'\u001b[39m\u001b[33mtop_p\u001b[39m\u001b[33m'\u001b[39m, NOT_GIVEN),\n\u001b[32m    245\u001b[39m         timeout=model_settings.get(\u001b[33m'\u001b[39m\u001b[33mtimeout\u001b[39m\u001b[33m'\u001b[39m, NOT_GIVEN),\n\u001b[32m    246\u001b[39m         metadata=model_settings.get(\u001b[33m'\u001b[39m\u001b[33manthropic_metadata\u001b[39m\u001b[33m'\u001b[39m, NOT_GIVEN),\n\u001b[32m    247\u001b[39m     )\n\u001b[32m    248\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m APIStatusError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/1_github/Exploring_the_World_of_Programming_with_Python/.venv/lib/python3.13/site-packages/anthropic/resources/messages/messages.py:2165\u001b[39m, in \u001b[36mAsyncMessages.create\u001b[39m\u001b[34m(self, max_tokens, messages, model, metadata, stop_sequences, stream, system, temperature, thinking, tool_choice, tools, top_k, top_p, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m   2159\u001b[39m     warnings.warn(\n\u001b[32m   2160\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mThe model \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m is deprecated and will reach end-of-life on \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mDEPRECATED_MODELS[model]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mPlease migrate to a newer model. Visit https://docs.anthropic.com/en/docs/resources/model-deprecations for more information.\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   2161\u001b[39m         \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m,\n\u001b[32m   2162\u001b[39m         stacklevel=\u001b[32m3\u001b[39m,\n\u001b[32m   2163\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m2165\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._post(\n\u001b[32m   2166\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m/v1/messages\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   2167\u001b[39m     body=\u001b[38;5;28;01mawait\u001b[39;00m async_maybe_transform(\n\u001b[32m   2168\u001b[39m         {\n\u001b[32m   2169\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mmax_tokens\u001b[39m\u001b[33m\"\u001b[39m: max_tokens,\n\u001b[32m   2170\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m: messages,\n\u001b[32m   2171\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m: model,\n\u001b[32m   2172\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mmetadata\u001b[39m\u001b[33m\"\u001b[39m: metadata,\n\u001b[32m   2173\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mstop_sequences\u001b[39m\u001b[33m\"\u001b[39m: stop_sequences,\n\u001b[32m   2174\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m: stream,\n\u001b[32m   2175\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33msystem\u001b[39m\u001b[33m\"\u001b[39m: system,\n\u001b[32m   2176\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mtemperature\u001b[39m\u001b[33m\"\u001b[39m: temperature,\n\u001b[32m   2177\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mthinking\u001b[39m\u001b[33m\"\u001b[39m: thinking,\n\u001b[32m   2178\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mtool_choice\u001b[39m\u001b[33m\"\u001b[39m: tool_choice,\n\u001b[32m   2179\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mtools\u001b[39m\u001b[33m\"\u001b[39m: tools,\n\u001b[32m   2180\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mtop_k\u001b[39m\u001b[33m\"\u001b[39m: top_k,\n\u001b[32m   2181\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mtop_p\u001b[39m\u001b[33m\"\u001b[39m: top_p,\n\u001b[32m   2182\u001b[39m         },\n\u001b[32m   2183\u001b[39m         message_create_params.MessageCreateParams,\n\u001b[32m   2184\u001b[39m     ),\n\u001b[32m   2185\u001b[39m     options=make_request_options(\n\u001b[32m   2186\u001b[39m         extra_headers=extra_headers, extra_query=extra_query, extra_body=extra_body, timeout=timeout\n\u001b[32m   2187\u001b[39m     ),\n\u001b[32m   2188\u001b[39m     cast_to=Message,\n\u001b[32m   2189\u001b[39m     stream=stream \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m   2190\u001b[39m     stream_cls=AsyncStream[RawMessageStreamEvent],\n\u001b[32m   2191\u001b[39m )\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/1_github/Exploring_the_World_of_Programming_with_Python/.venv/lib/python3.13/site-packages/anthropic/_base_client.py:1920\u001b[39m, in \u001b[36mAsyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, files, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1917\u001b[39m opts = FinalRequestOptions.construct(\n\u001b[32m   1918\u001b[39m     method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=\u001b[38;5;28;01mawait\u001b[39;00m async_to_httpx_files(files), **options\n\u001b[32m   1919\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m1920\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/1_github/Exploring_the_World_of_Programming_with_Python/.venv/lib/python3.13/site-packages/anthropic/_base_client.py:1614\u001b[39m, in \u001b[36mAsyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls, remaining_retries)\u001b[39m\n\u001b[32m   1612\u001b[39m     retries_taken = \u001b[32m0\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1614\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._request(\n\u001b[32m   1615\u001b[39m     cast_to=cast_to,\n\u001b[32m   1616\u001b[39m     options=options,\n\u001b[32m   1617\u001b[39m     stream=stream,\n\u001b[32m   1618\u001b[39m     stream_cls=stream_cls,\n\u001b[32m   1619\u001b[39m     retries_taken=retries_taken,\n\u001b[32m   1620\u001b[39m )\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/1_github/Exploring_the_World_of_Programming_with_Python/.venv/lib/python3.13/site-packages/anthropic/_base_client.py:1715\u001b[39m, in \u001b[36mAsyncAPIClient._request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls, retries_taken)\u001b[39m\n\u001b[32m   1714\u001b[39m     log.debug(\u001b[33m\"\u001b[39m\u001b[33mRe-raising status error\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1715\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._make_status_error_from_response(err.response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1717\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._process_response(\n\u001b[32m   1718\u001b[39m     cast_to=cast_to,\n\u001b[32m   1719\u001b[39m     options=options,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1723\u001b[39m     retries_taken=retries_taken,\n\u001b[32m   1724\u001b[39m )\n",
            "\u001b[31mBadRequestError\u001b[39m: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'Your credit balance is too low to access the Anthropic API. Please go to Plans & Billing to upgrade or purchase credits.'}}",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[31mModelHTTPError\u001b[39m                            Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m      9\u001b[39m                 debug([e.data_snapshot() \u001b[38;5;28;01mfor\u001b[39;00m e \u001b[38;5;129;01min\u001b[39;00m history])\n\u001b[32m     10\u001b[39m                 \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m result = \u001b[38;5;28;01mawait\u001b[39;00m run_automated_joke_generator()\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 7\u001b[39m, in \u001b[36mrun_automated_joke_generator\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m logfire.span(\u001b[33m'\u001b[39m\u001b[33mrun automated joke generator\u001b[39m\u001b[33m'\u001b[39m):\n\u001b[32m      6\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m         node = \u001b[38;5;28;01mawait\u001b[39;00m question_graph.next(node, history, state=state)\n\u001b[32m      8\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(node, End):\n\u001b[32m      9\u001b[39m             debug([e.data_snapshot() \u001b[38;5;28;01mfor\u001b[39;00m e \u001b[38;5;129;01min\u001b[39;00m history])\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/1_github/Exploring_the_World_of_Programming_with_Python/.venv/lib/python3.13/site-packages/pydantic_graph/graph.py:307\u001b[39m, in \u001b[36mGraph.next\u001b[39m\u001b[34m(self, node, history, state, deps, infer_name)\u001b[39m\n\u001b[32m    305\u001b[39m     start_ts = _utils.now_utc()\n\u001b[32m    306\u001b[39m     start = perf_counter()\n\u001b[32m--> \u001b[39m\u001b[32m307\u001b[39m     next_node = \u001b[38;5;28;01mawait\u001b[39;00m node.run(ctx)\n\u001b[32m    308\u001b[39m     duration = perf_counter() - start\n\u001b[32m    310\u001b[39m history.append(\n\u001b[32m    311\u001b[39m     NodeStep(state=state, node=node, start_ts=start_ts, duration=duration, snapshot_state=\u001b[38;5;28mself\u001b[39m.snapshot_state)\n\u001b[32m    312\u001b[39m )\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 19\u001b[39m, in \u001b[36mJokeGenerator.run\u001b[39m\u001b[34m(self, ctx)\u001b[39m\n\u001b[32m     10\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.feedback:\n\u001b[32m     11\u001b[39m             prompt = \u001b[33mf\u001b[39m\u001b[33m\"\"\"\u001b[39m\u001b[33mInvente uma piada sobre gatos. Ela deve ser engraçada e interessante.\u001b[39m\n\u001b[32m     12\u001b[39m \n\u001b[32m     13\u001b[39m \u001b[33mTentativa anterior: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mctx.state.joke\u001b[38;5;132;01m}\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     16\u001b[39m \n\u001b[32m     17\u001b[39m \u001b[33mPor favor, crie uma nova piada que aborde este feedback.\u001b[39m\u001b[33m\"\"\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m         result = \u001b[38;5;28;01mawait\u001b[39;00m joke_generator_agent.run(\n\u001b[32m     20\u001b[39m             prompt,\n\u001b[32m     21\u001b[39m             message_history=ctx.state.joke_generator_agent_messages,\n\u001b[32m     22\u001b[39m         )\n\u001b[32m     23\u001b[39m         ctx.state.joke_generator_agent_messages += result.all_messages()\n\u001b[32m     24\u001b[39m         ctx.state.joke = result.data\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/1_github/Exploring_the_World_of_Programming_with_Python/.venv/lib/python3.13/site-packages/pydantic_ai/agent.py:316\u001b[39m, in \u001b[36mAgent.run\u001b[39m\u001b[34m(self, user_prompt, result_type, message_history, model, deps, model_settings, usage_limits, usage, infer_name)\u001b[39m\n\u001b[32m    305\u001b[39m     \u001b[38;5;28mself\u001b[39m._infer_name(inspect.currentframe())\n\u001b[32m    306\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m.iter(\n\u001b[32m    307\u001b[39m     user_prompt=user_prompt,\n\u001b[32m    308\u001b[39m     result_type=result_type,\n\u001b[32m   (...)\u001b[39m\u001b[32m    314\u001b[39m     usage=usage,\n\u001b[32m    315\u001b[39m ) \u001b[38;5;28;01mas\u001b[39;00m agent_run:\n\u001b[32m--> \u001b[39m\u001b[32m316\u001b[39m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m agent_run:\n\u001b[32m    317\u001b[39m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m    319\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m (final_result := agent_run.result) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[33m'\u001b[39m\u001b[33mThe graph run did not finish properly\u001b[39m\u001b[33m'\u001b[39m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/1_github/Exploring_the_World_of_Programming_with_Python/.venv/lib/python3.13/site-packages/pydantic_ai/agent.py:1366\u001b[39m, in \u001b[36mAgentRun.__anext__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1362\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__anext__\u001b[39m(\n\u001b[32m   1363\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1364\u001b[39m ) -> _agent_graph.AgentNode[AgentDepsT, ResultDataT] | End[FinalResult[ResultDataT]]:\n\u001b[32m   1365\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Advance to the next node automatically based on the last returned node.\"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1366\u001b[39m     next_node = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._graph_run.\u001b[34m__anext__\u001b[39m()\n\u001b[32m   1367\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m _agent_graph.is_agent_node(next_node):\n\u001b[32m   1368\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m next_node\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/1_github/Exploring_the_World_of_Programming_with_Python/.venv/lib/python3.13/site-packages/pydantic_graph/graph.py:736\u001b[39m, in \u001b[36mGraphRun.__anext__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    734\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m._next_node, End):\n\u001b[32m    735\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopAsyncIteration\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m736\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.next(\u001b[38;5;28mself\u001b[39m._next_node)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/1_github/Exploring_the_World_of_Programming_with_Python/.venv/lib/python3.13/site-packages/pydantic_graph/graph.py:725\u001b[39m, in \u001b[36mGraphRun.next\u001b[39m\u001b[34m(self, node)\u001b[39m\n\u001b[32m    722\u001b[39m state = \u001b[38;5;28mself\u001b[39m.state\n\u001b[32m    723\u001b[39m deps = \u001b[38;5;28mself\u001b[39m.deps\n\u001b[32m--> \u001b[39m\u001b[32m725\u001b[39m \u001b[38;5;28mself\u001b[39m._next_node = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.graph.next(node, history, state=state, deps=deps, infer_name=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m    727\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._next_node\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/1_github/Exploring_the_World_of_Programming_with_Python/.venv/lib/python3.13/site-packages/pydantic_graph/graph.py:307\u001b[39m, in \u001b[36mGraph.next\u001b[39m\u001b[34m(self, node, history, state, deps, infer_name)\u001b[39m\n\u001b[32m    305\u001b[39m     start_ts = _utils.now_utc()\n\u001b[32m    306\u001b[39m     start = perf_counter()\n\u001b[32m--> \u001b[39m\u001b[32m307\u001b[39m     next_node = \u001b[38;5;28;01mawait\u001b[39;00m node.run(ctx)\n\u001b[32m    308\u001b[39m     duration = perf_counter() - start\n\u001b[32m    310\u001b[39m history.append(\n\u001b[32m    311\u001b[39m     NodeStep(state=state, node=node, start_ts=start_ts, duration=duration, snapshot_state=\u001b[38;5;28mself\u001b[39m.snapshot_state)\n\u001b[32m    312\u001b[39m )\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/1_github/Exploring_the_World_of_Programming_with_Python/.venv/lib/python3.13/site-packages/pydantic_ai/_agent_graph.py:252\u001b[39m, in \u001b[36mModelRequestNode.run\u001b[39m\u001b[34m(self, ctx)\u001b[39m\n\u001b[32m    247\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._did_stream:\n\u001b[32m    248\u001b[39m     \u001b[38;5;66;03m# `self._result` gets set when exiting the `stream` contextmanager, so hitting this\u001b[39;00m\n\u001b[32m    249\u001b[39m     \u001b[38;5;66;03m# means that the stream was started but not finished before `run()` was called\u001b[39;00m\n\u001b[32m    250\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions.AgentRunError(\u001b[33m'\u001b[39m\u001b[33mYou must finish streaming before calling run()\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m252\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._make_request(ctx)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/1_github/Exploring_the_World_of_Programming_with_Python/.venv/lib/python3.13/site-packages/pydantic_ai/_agent_graph.py:304\u001b[39m, in \u001b[36mModelRequestNode._make_request\u001b[39m\u001b[34m(self, ctx)\u001b[39m\n\u001b[32m    301\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._result\n\u001b[32m    303\u001b[39m model_settings, model_request_parameters = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._prepare_request(ctx)\n\u001b[32m--> \u001b[39m\u001b[32m304\u001b[39m model_response, request_usage = \u001b[38;5;28;01mawait\u001b[39;00m ctx.deps.model.request(\n\u001b[32m    305\u001b[39m     ctx.state.message_history, model_settings, model_request_parameters\n\u001b[32m    306\u001b[39m )\n\u001b[32m    307\u001b[39m ctx.state.usage.incr(_usage.Usage(), requests=\u001b[32m1\u001b[39m)\n\u001b[32m    309\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._finish_handling(ctx, model_response, request_usage)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/1_github/Exploring_the_World_of_Programming_with_Python/.venv/lib/python3.13/site-packages/pydantic_ai/models/instrumented.py:116\u001b[39m, in \u001b[36mInstrumentedModel.request\u001b[39m\u001b[34m(self, messages, model_settings, model_request_parameters)\u001b[39m\n\u001b[32m    109\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrequest\u001b[39m(\n\u001b[32m    110\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    111\u001b[39m     messages: \u001b[38;5;28mlist\u001b[39m[ModelMessage],\n\u001b[32m    112\u001b[39m     model_settings: ModelSettings | \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    113\u001b[39m     model_request_parameters: ModelRequestParameters,\n\u001b[32m    114\u001b[39m ) -> \u001b[38;5;28mtuple\u001b[39m[ModelResponse, Usage]:\n\u001b[32m    115\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._instrument(messages, model_settings) \u001b[38;5;28;01mas\u001b[39;00m finish:\n\u001b[32m--> \u001b[39m\u001b[32m116\u001b[39m         response, usage = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().request(messages, model_settings, model_request_parameters)\n\u001b[32m    117\u001b[39m         finish(response, usage)\n\u001b[32m    118\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m response, usage\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/1_github/Exploring_the_World_of_Programming_with_Python/.venv/lib/python3.13/site-packages/pydantic_ai/models/wrapper.py:24\u001b[39m, in \u001b[36mWrapperModel.request\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     23\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrequest\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args: Any, **kwargs: Any) -> \u001b[38;5;28mtuple\u001b[39m[ModelResponse, Usage]:\n\u001b[32m---> \u001b[39m\u001b[32m24\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.wrapped.request(*args, **kwargs)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/1_github/Exploring_the_World_of_Programming_with_Python/.venv/lib/python3.13/site-packages/pydantic_ai/models/anthropic.py:161\u001b[39m, in \u001b[36mAnthropicModel.request\u001b[39m\u001b[34m(self, messages, model_settings, model_request_parameters)\u001b[39m\n\u001b[32m    154\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrequest\u001b[39m(\n\u001b[32m    155\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    156\u001b[39m     messages: \u001b[38;5;28mlist\u001b[39m[ModelMessage],\n\u001b[32m    157\u001b[39m     model_settings: ModelSettings | \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    158\u001b[39m     model_request_parameters: ModelRequestParameters,\n\u001b[32m    159\u001b[39m ) -> \u001b[38;5;28mtuple\u001b[39m[ModelResponse, usage.Usage]:\n\u001b[32m    160\u001b[39m     check_allow_model_requests()\n\u001b[32m--> \u001b[39m\u001b[32m161\u001b[39m     response = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._messages_create(\n\u001b[32m    162\u001b[39m         messages, \u001b[38;5;28;01mFalse\u001b[39;00m, cast(AnthropicModelSettings, model_settings \u001b[38;5;129;01mor\u001b[39;00m {}), model_request_parameters\n\u001b[32m    163\u001b[39m     )\n\u001b[32m    164\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._process_response(response), _map_usage(response)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/1_github/Exploring_the_World_of_Programming_with_Python/.venv/lib/python3.13/site-packages/pydantic_ai/models/anthropic.py:250\u001b[39m, in \u001b[36mAnthropicModel._messages_create\u001b[39m\u001b[34m(self, messages, stream, model_settings, model_request_parameters)\u001b[39m\n\u001b[32m    248\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m APIStatusError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    249\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m (status_code := e.status_code) >= \u001b[32m400\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m250\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m ModelHTTPError(status_code=status_code, model_name=\u001b[38;5;28mself\u001b[39m.model_name, body=e.body) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m    251\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
            "\u001b[31mModelHTTPError\u001b[39m: status_code: 400, model_name: claude-3-7-sonnet-latest, body: {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'Your credit balance is too low to access the Anthropic API. Please go to Plans & Billing to upgrade or purchase credits.'}}"
          ]
        }
      ],
      "source": [
        "async def run_automated_joke_generator():\n",
        "    state = JokeState()\n",
        "    node = JokeGenerator()\n",
        "    history: list[HistoryStep[JokeState, None]] = []\n",
        "    with logfire.span('run automated joke generator'):\n",
        "        while True:\n",
        "            node = await question_graph.next(node, history, state=state)\n",
        "            if isinstance(node, End):\n",
        "                debug([e.data_snapshot() for e in history])\n",
        "                break\n",
        "\n",
        "result = await run_automated_joke_generator()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
