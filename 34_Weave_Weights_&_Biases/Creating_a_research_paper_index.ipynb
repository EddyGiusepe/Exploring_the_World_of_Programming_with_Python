{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <h1 align=\"center\"><font color=\"gree\">Building reliable apps with GPT-4o and structured outputs</font></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"pink\">Senior Data Scientist.: Dr. Eddy Giusepe Chirinos Isidro</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Link de estudo:\n",
    "\n",
    "* [Weights & Biases](https://wandb.ai/byyoung3/ML_NEWS3/reports/Building-reliable-apps-with-GPT-4o-and-structured-outputs--Vmlldzo5NjM3MDU5?utm_source=send&utm_medium=email&utm_campaign=weave_newsletter&mkt_tok=MjYxLVFIUC04MjIAAAGWVTi_9ukc1NwoPluktU9oVF5Gheg-LxEy_B2xoCs4t_i8_wZVyi4J7kaogJxOF8BM9X2-cn1sxz5WnzLqtNXO-Vv5dgYzps2hmSj6NFOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weave version 0.51.14 has been recalled!  (Evaluation framework is mis-reporting the inputs for prediction records)  Please upgrade.\n",
      "Logged in as Weights & Biases user: eddygiusepe.\n",
      "View Weave data at https://wandb.ai/eddygiusepe/paper_classification/weave\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import arxiv\n",
    "import shutil\n",
    "from PyPDF2 import PdfReader\n",
    "from openai import OpenAI\n",
    "import weave\n",
    "\n",
    "#from openai import OpenAI\n",
    "#client = OpenAI(api_key=Eddy_key_openai)\n",
    "\n",
    "# Initialize Weave and OpenAI\n",
    "weave.init(\"paper_classification\")\n",
    "\n",
    "import openai\n",
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "#openai.api_key  = os.environ['OPENAI_API_KEY']\n",
    "Eddy_key_openai = os.environ['OPENAI_API_KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"gpt-4o-2024-08-06\" #\"gpt-4o-mini\" # gpt-4o-2024-08-06\n",
    "client = OpenAI(api_key=Eddy_key_openai)\n",
    "\n",
    "\n",
    "# Directory to download and categorize papers\n",
    "download_dir = \"./arxiv_papers\"\n",
    "if not os.path.exists(download_dir):\n",
    "    os.makedirs(download_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of machine learning categories\n",
    "categories = [\n",
    "    \"Supervised Learning\", \"Unsupervised Learning\", \"Reinforcement Learning\", \"Deep Learning\", \n",
    "    \"Natural Language Processing\", \"Computer Vision\", \"Graph Neural Networks\", \"Transfer Learning\", \n",
    "    \"Meta-Learning\", \"Few-Shot Learning\", \"Self-Supervised Learning\", \"Representation Learning\", \n",
    "    \"Multi-Modal Learning\", \"Generative Adversarial Networks (GANs)\", \"Bayesian Methods\", \n",
    "    \"Probabilistic Models\", \"Federated Learning\", \"Privacy-Preserving ML\", \"Fairness and Bias in ML\", \n",
    "    \"Explainable AI\", \"Optimization Algorithms\", \"Adversarial Robustness\", \"Causal Inference\", \n",
    "    \"Anomaly Detection\", \"Time Series Analysis\", \"Graph-Based Learning\", \"Knowledge Graphs\", \n",
    "    \"Ontology Learning\", \"Recommender Systems\", \"Information Retrieval\", \"Domain Adaptation\", \n",
    "    \"Semi-Supervised Learning\", \"Data Augmentation Techniques\", \"Multi-Agent Systems\", \n",
    "    \"Human-in-the-Loop Learning\", \"Curriculum Learning\", \"Active Learning\", \"Imitation Learning\", \n",
    "    \"Inverse Reinforcement Learning\", \"Policy Optimization\", \"Robustness to Distribution Shifts\", \n",
    "    \"Neural Architecture Search (NAS)\", \"Hyperparameter Optimization\", \"Neurosymbolic AI\", \n",
    "    \"Neural Ordinary Differential Equations\", \"Memory-Augmented Networks\", \"Recurrent Neural Networks (RNNs)\", \n",
    "    \"Long Short-Term Memory (LSTM)\", \"Transformer Models\", \"Attention Mechanisms\", \n",
    "    \"Pre-trained Language Models (e.g., BERT, GPT)\", \"Contrastive Learning\", \"Energy-Based Models\", \n",
    "    \"Neural Style Transfer\", \"Object Detection\", \"Segmentation Models\", \"Image Generation\", \"3D Vision\", \n",
    "    \"Motion Prediction\", \"Speech Recognition\", \"Speech Synthesis\", \"Emotion Recognition\", \n",
    "    \"Text Generation\", \"Summarization\", \"Machine Translation\", \"Question Answering\", \"Dialogue Systems\", \n",
    "    \"Conversational AI\", \"Autonomous Systems\", \"Robotics and Control\", \"Game Theory in ML\", \n",
    "    \"Synthetic Data Generation\", \"Biomedical Data Analysis\", \"Bioinformatics\", \"Healthcare Applications of ML\", \n",
    "    \"Drug Discovery\", \"Predictive Maintenance\", \"Financial Modeling\", \"Climate Modeling\", \n",
    "    \"Physics-Informed Learning\", \"Chemistry Applications\", \"Material Science Applications\", \n",
    "    \"Social Network Analysis\", \"Sentiment Analysis\", \"Text Mining\", \"Data Mining\", \"Complex Systems\", \n",
    "    \"Ensemble Methods\", \"Evolutionary Algorithms\", \"Quantum Machine Learning\", \"ML System Performance Optimization\", \n",
    "    \"ML in Edge Computing\", \"ML for Internet of Things (IoT)\", \"Multi-Task Learning\", \"Continual Learning\", \n",
    "    \"Neural-Symbolic Learning\", \"Vision-Language Models\", \"Zero-Shot Learning\", \"Learning from Demonstration\", \n",
    "    \"Neural Network Pruning\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to read the first 1000 characters of a PDF\n",
    "def read_pdf_first_1000_chars(pdf_path):\n",
    "    try:\n",
    "        with open(pdf_path, 'rb') as file:\n",
    "            reader = PdfReader(file)\n",
    "            text = \"\"\n",
    "            for page in reader.pages:\n",
    "                text += page.extract_text()\n",
    "                if len(text) >= 1000:\n",
    "                    return text[:1000]\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to read {pdf_path}: {e}\")\n",
    "    return \"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to categorize a paper based on its content using structured output\n",
    "@weave.op\n",
    "def categorize_paper(text):\n",
    "    # Define the JSON schema for structured output with enum categories (not required but helpful) \n",
    "    category_schema = {\n",
    "        \"type\": \"json_schema\",\n",
    "        \"json_schema\": {\n",
    "            \"name\": \"paper_category_response\",\n",
    "            \"schema\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"category\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"enum\": categories,  # Use the list of categories as enum options\n",
    "                        \"description\": \"The category of the research paper\"\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"category\"],  # Ensure that the response contains a category\n",
    "                \"additionalProperties\": False,\n",
    "                \"strict\": True\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "\n",
    "    # Create the prompt for categorizing the text\n",
    "    prompt = f\"\"\"\n",
    "    Com base no texto a seguir de um artigo de pesquisa, categorize-o em um dos seguintes t√≥picos de aprendizado de m√°quina: {', '.join(categories)}.\n",
    "    Por favor, responda com um objeto JSON no formato: {{\"category\": \"Category Name\"}}.\n",
    "\n",
    "\n",
    "    Research Paper Content:\n",
    "    {text}\n",
    "    \"\"\"\n",
    "    \n",
    "    # Make the API request to categorize the text using structured output\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"Voc√™ √© um assistente de categoriza√ß√£o.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        response_format=category_schema,  # Use structured output format with enum\n",
    "        max_tokens=50,\n",
    "        temperature=0.3\n",
    "    )\n",
    "    \n",
    "    # Parse the model's response to extract the category\n",
    "    result = response.choices[0].message.content.strip()\n",
    "    try:\n",
    "        result_json = json.loads(result)\n",
    "        category = result_json.get(\"category\", \"Uncategorized\")\n",
    "    except json.JSONDecodeError:\n",
    "        category = \"Uncategorized\"\n",
    "\n",
    "\n",
    "    return category\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to move the PDF to the appropriate category folder\n",
    "def move_pdf_to_category(pdf_path, category):\n",
    "    category_dir = os.path.join(download_dir, category.replace(\" \", \"_\"))\n",
    "    if not os.path.exists(category_dir):\n",
    "        os.makedirs(category_dir)\n",
    "    shutil.move(pdf_path, os.path.join(category_dir, os.path.basename(pdf_path)))\n",
    "    print(f\"Moved {pdf_path} to {category_dir}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download recent papers from arXiv\n",
    "query = \"Paper sobre Aten√ß√£o √© tudo o que precisamos\"\n",
    "max_results = 1  # Change to a larger number as needed\n",
    "search = arxiv.Search(\n",
    "    query=query,\n",
    "    max_results=max_results,\n",
    "    sort_by=arxiv.SortCriterion.SubmittedDate\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_18138/817328682.py:2: DeprecationWarning: The 'Search.results' method is deprecated, use 'Client.results' instead\n",
      "  for result in search.results():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading: Detection of Undeclared EV Charging Events in a Green Energy Certification Scheme\n",
      "Categorizing paper: 2410.18971v1.pdf\n",
      "üç© https://wandb.ai/eddygiusepe/paper_classification/r/call/0192cf0c-452f-7cd1-95fc-a4f32b93823f\n",
      "Assigned Category: Supervised Learning\n",
      "Moved ./arxiv_papers/2410.18971v1.pdf to ./arxiv_papers/Supervised_Learning\n"
     ]
    }
   ],
   "source": [
    "# Iterate through each result and categorize the paper\n",
    "for result in search.results():\n",
    "    print(f\"Downloading: {result.title}\")\n",
    "    paper_id = result.entry_id.split('/')[-1]\n",
    "    pdf_url = result.pdf_url\n",
    "    filename = f\"{paper_id}.pdf\"\n",
    "    result.download_pdf(dirpath=download_dir, filename=filename)\n",
    "    \n",
    "    # Read the first 100 characters of the downloaded PDF\n",
    "    pdf_path = os.path.join(download_dir, filename)\n",
    "    text_snippet = read_pdf_first_1000_chars(pdf_path)\n",
    "    \n",
    "    if text_snippet:\n",
    "        print(f\"Categorizing paper: {filename}\")\n",
    "        # Use the categorize_paper function to get the category\n",
    "        category = categorize_paper(text_snippet)\n",
    "        print(f\"Assigned Category: {category}\")\n",
    "        \n",
    "        # Move the PDF to the appropriate category folder\n",
    "        move_pdf_to_category(pdf_path, category)\n",
    "    else:\n",
    "        print(f\"Failed to extract text from {filename}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_All",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
