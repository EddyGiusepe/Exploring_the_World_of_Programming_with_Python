{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <h1 align=\"center\"><font color=\"gree\">Qwen2-VL: Hands-On Guides for Invoice Data Extraction, Video Chatting, and Multimodal RAG with PDFs</font></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"pink\">Senior Data Scientist.: Dr. Eddy Giusepe Chirinos Isidro</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este Notebook segue o tutorial de [Nikos Kafritsas](https://aihorizonforecast.substack.com/p/qwen2-vl-hands-on-guides-for-invoice). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Links adicionais:\n",
    "\n",
    "* Para testar no `Hugging Face`: [Qwen2-VL-Max é o nome da Interface no Gradio](https://huggingface.co/spaces/Qwen/Qwen2-VL) \n",
    "\n",
    "`O nome do modelo 'qwen-vl-max-0809' é a identidade de 'Qwen2-VL-72B'.`\n",
    "\n",
    "* [GitHub: Qwen2-VL](https://github.com/QwenLM/Qwen2-VL)\n",
    "\n",
    "* [Qwen's collections](https://huggingface.co/collections/Qwen/qwen2-vl-66cee7455501d7126940800d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=\"red\">Como usar um modelo de linguagem de visão de código aberto de ponta?</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"orange\">A imagem abaixo mostra a `arquitetura` de nível superior do `Qwen2-VL`</font>\n",
    "\n",
    "\n",
    "O que se sabe até agora é que o `Qwen2-VL` usa o `Qwen2-LM` com um `Vision Transformer` — capaz de processar `imagens` e `vídeos`.\n",
    "\n",
    "Além disso, o `Qwen2-VL` introduz o novo `Multimodal Rotary Position Embeddings` (**M-ROPE**). Essa é uma variante dos `embeddings ROPE` (nós os discutimos brevemente [aqui](https://aihorizonforecast.substack.com/p/moirai-salesforces-foundation-transformer)) que decompõe os embeddings posicionais em partes — capturando `texto 1D`, `visual 2D` e `vídeo 3D`:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbf04e083-f0ef-4a9b-8784-ebecbfc52a78_1634x412.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Qwen2-VL` suporta vários idiomas, incluindo a maioria dos `idiomas europeus`, `japonês`, `coreano`, `chinês` e `árabe`. Mais detalhes estarão disponíveis quando o artigo oficial for lançado.\n",
    "\n",
    "\n",
    "<font color=\"red\">Nota:</font>\n",
    "\n",
    "`Qwen2-VL` vem em 3 tamanhos: `Qwen2-VL-2B`, `Qwen2-VL-7B` e `Qwen2-VL-72B`. As versões `2B` e `7B` são totalmente de `código aberto` (`Licença Apache`). A versão `72B é comercial`, mas gratuita para serviços com menos de 100 milhões de usuários ativos mensais.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffe3c34e0-f1e9-4fc8-9c73-915794e384e5_1656x1076.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O aumento de novos `LLMs` e `vLLMs` é imparável. Um modelo notável é o `Qwen2-VL` — um `Vision LM` com compreensão avançada de `imagem` e `vídeo`.\n",
    "\n",
    "Principais características do `Qwen2-VL`:\n",
    "\n",
    "* `Arquitetura poderosa:` Lançado pela `Alibaba`, é construído no Qwen2 LM.\n",
    "\n",
    "* `Reconhecimento de objetos e textos:` O `Qwen2-VL` reconhece relacionamentos complexos de objetos, textos manuscritos e vários idiomas.\n",
    "\n",
    "* `Raciocínio visual aprimorado:` o modelo resolve problemas de `matemática` e `codificação` a partir de gráficos e imagens, melhorando a extração de dados do mundo real.\n",
    "\n",
    "* `Compreensão de vídeo e bate-papo ao vivo:` fornece resumo de vídeo, resposta a perguntas e suporte por bate-papo em tempo real a partir de conteúdo de vídeo.\n",
    "\n",
    "* `Chamada de função (Function calling) e interações visuais:` o `Qwen2-VL` recupera dados em tempo real por meio de indicações visuais, como atualizações meteorológicas.\n",
    "\n",
    "\n",
    "\n",
    "Aqui seguimos o tutorial de `Nikos Kafritsas`, quem apresenta `3` guias práticos para usar o `Qwen2-VL`. Esses são:\n",
    "\n",
    "`1.` Extração de dados de imagem\n",
    "\n",
    "`2.` Conversando com vídeos\n",
    "\n",
    "`3.` RAG multimodal com PDFs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=\"blue\">`Project 1:` Invoice Data Extraction to JSON Format</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neste miniprojeto, extrairemos informações financeiras e pessoais de uma fatura — no formato `JSON`.\n",
    "\n",
    "Bibliotecas necessárias:\n",
    "\n",
    "```\n",
    "pip install git+https://github.com/huggingface/transformers accelerate\n",
    "\n",
    "pip install qwen-vl-utils\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Em seguida, baixamos nosso arquivo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded file name: service-invoice-template-1x.jpg\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "\n",
    "# We will use this sample invoice:\n",
    "url = \"https://www.zoho.com/invoice/images/invoice-templates/service-invoice-template/service-invoice-template-1x.jpg\"\n",
    "\n",
    "# Download the file:\n",
    "file_name = url.split('/')[-1]\n",
    "urllib.request.urlretrieve(url, file_name)\n",
    "\n",
    "print(f\"Downloaded file name: {file_name}\")\n",
    "# Downloaded file name: service-invoice-template-1x.jpg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Em seguida, instalaremos `Qwen2-VL-2B-Instruct` — a versão menor, menos precisa, mas compatível com `VRAM` para execução no Colab.\n",
    "\n",
    "Sinta-se à vontade para tentar `Qwen2-VL-7B-Instruct` se você tiver uma `GPU` maior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Qwen2VLRotaryEmbedding` can now be fully parameterized by passing the model config through the `config` argument. All other arguments will be removed in v4.46\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6626f75f2b2e42cc874dbce15a6ce774",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import Qwen2VLForConditionalGeneration, AutoTokenizer, AutoProcessor\n",
    "from qwen_vl_utils import process_vision_info\n",
    "import json\n",
    "\n",
    "model_name = \"Qwen/Qwen2-VL-2B-Instruct\" # Qwen/Qwen2-VL-7B-Instruct    ou     Qwen/Qwen2-VL-72B-Instruct\n",
    "model = Qwen2VLForConditionalGeneration.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype=\"auto\",\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(\n",
    "    model_name\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Após o modelo ser baixado e colocado na memória, podemos enviar nossa solicitação. Algumas dicas extras:\n",
    "\n",
    "Use pelo menos as dimensões originais da imagem : certifique-se de usar pelo menos o tamanho original da sua imagem para obter melhores resultados ( resized_height e resized_width arguments abaixo)\n",
    "\n",
    "Dimensões maiores : Tamanhos de dimensões ligeiramente maiores em imagens de baixa qualidade podem melhorar a precisão, mas aumentarão o uso de VRAM. Ajuste de acordo:\n",
    "\n",
    "Usaremos o modelo de bate-papo do Qwen2-VL com o seguinte prompt:\n",
    "\n",
    "```\n",
    "\"Retrieve invoice_number, date_of_issue, seller_info, client_info, invoice_items_table, invoice_summary_table. Response must be in JSON format\"\n",
    "```\n",
    "ou em português:\n",
    "\n",
    "```\n",
    "Recuperar invoice_number, date_of_issue, seller_info, client_info, invoice_items_table, invoice_summary_table. A resposta deve estar no formato JSON\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['```json\\n{\\n  \"invoice_number\": \"INV-000001\",\\n  \"date_of_issue\": \"18 May 2023\",\\n  \"seller_info\": {\\n    \"name\": \"Zylker Design Labs\",\\n    \"address\": \"14B, Northern Street, Greater South Avenue, New York, New York 10001, U.S.A.\"\\n  },\\n  \"client_info\": {\\n    \"name\": \"Jack Little\",\\n    \"address\": \"3242 Chandler Hollow Road, Pittsburgh, Pennsylvania 15222, Pennsylvania\"\\n  },\\n  \"invoice_items_table\": [\\n    {\\n      \"item\": \"Brochure Design\",\\n      \"description\": \"Brochure design - Single sided (Color)\",\\n      \"quantity\": 1,\\n      \"rate\": 900.00,\\n      \"amount\": 900.00\\n    },\\n    {\\n      \"item\": \"Web Design packages (Simple)\",\\n      \"description\": \"10 Pages, Slider, Free Logo, Dynamic Website, Free Domain, Hosting Free for 1st year\",\\n      \"quantity\": 1,\\n      \"rate\": 10000.00,\\n      \"amount\": 10000.00\\n    },\\n    {\\n      \"item\": \"Print Ad - Newspaper\",\\n      \"description\": \"A full-page ad, Nationwide Circulation (Color)\",\\n      \"quantity\": 1,\\n      \"rate\": 7500.00,\\n      \"amount\": 7500.00\\n    }\\n  ],\\n  \"invoice_summary_table\": [\\n    {\\n      \"subtotal\": 18400.00,\\n      \"tax_rate\": 5.00,\\n      \"total\": 19320.00\\n    }\\n  ],\\n  \"notes\": \"Thanks for your business.\",\\n  \"terms_and_conditions\": \"All payments must be made in full before the commencement of any design work.\"\\n}\\n```']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = [{\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"\"\"Você é um assistente de extração de dados.\n",
    "                   \"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\n",
    "                \"type\": \"image\",\n",
    "                \"image\": file_name,\n",
    "                \"resized_height\": 696,\n",
    "                \"resized_width\": 943,\n",
    "            },\n",
    "            {\n",
    "                \"type\": \"text\",\n",
    "                \"text\": \"\"\"Recuperar invoice_number, date_of_issue, seller_info, client_info,\n",
    "                           invoice_items_table, invoice_summary_table. A resposta deve estar\n",
    "                           no formato JSON\"\"\"\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "]\n",
    "\n",
    "text = processor.apply_chat_template(\n",
    "    messages, tokenize=False, add_generation_prompt=True\n",
    ")\n",
    "\n",
    "image_inputs, video_inputs = process_vision_info(messages)\n",
    "inputs = processor(\n",
    "    text=[text],\n",
    "    images=image_inputs,\n",
    "    videos=video_inputs,\n",
    "    padding=True,\n",
    "    return_tensors=\"pt\",\n",
    ")\n",
    "inputs = inputs.to(\"cuda\")\n",
    "\n",
    "generated_ids = model.generate(**inputs, max_new_tokens=512)\n",
    "generated_ids_trimmed = [\n",
    "    out_ids[len(in_ids) :] for in_ids, out_ids in zip(inputs.input_ids, generated_ids)\n",
    "]\n",
    "output_text = processor.batch_decode(\n",
    "    generated_ids_trimmed, skip_special_tokens=True, clean_up_tokenization_spaces=True)\n",
    "\n",
    "output_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"orange\">Você pode usar o código abaixo para corrigir possíveis erros e formatar a saída `JSON` do modelo:</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "   \"invoice_number\": \"INV-000001\",\n",
      "   \"date_of_issue\": \"18 May 2023\",\n",
      "   \"seller_info\": {\n",
      "      \"name\": \"Zylker Design Labs\",\n",
      "      \"address\": \"14B, Northern Street, Greater South Avenue, New York, New York 10001, U.S.A.\"\n",
      "   },\n",
      "   \"client_info\": {\n",
      "      \"name\": \"Jack Little\",\n",
      "      \"address\": \"3242 Chandler Hollow Road, Pittsburgh, Pennsylvania 15222, Pennsylvania\"\n",
      "   },\n",
      "   \"invoice_items_table\": [\n",
      "      {\n",
      "         \"item\": \"Brochure Design\",\n",
      "         \"description\": \"Brochure design - Single sided (Color)\",\n",
      "         \"quantity\": 1,\n",
      "         \"rate\": 900.0,\n",
      "         \"amount\": 900.0\n",
      "      },\n",
      "      {\n",
      "         \"item\": \"Web Design packages (Simple)\",\n",
      "         \"description\": \"10 Pages, Slider, Free Logo, Dynamic Website, Free Domain, Hosting Free for 1st year\",\n",
      "         \"quantity\": 1,\n",
      "         \"rate\": 10000.0,\n",
      "         \"amount\": 10000.0\n",
      "      },\n",
      "      {\n",
      "         \"item\": \"Print Ad - Newspaper\",\n",
      "         \"description\": \"A full-page ad, Nationwide Circulation (Color)\",\n",
      "         \"quantity\": 1,\n",
      "         \"rate\": 7500.0,\n",
      "         \"amount\": 7500.0\n",
      "      }\n",
      "   ],\n",
      "   \"invoice_summary_table\": [\n",
      "      {\n",
      "         \"subtotal\": 18400.0,\n",
      "         \"tax_rate\": 5.0,\n",
      "         \"total\": 19320.0\n",
      "      }\n",
      "   ],\n",
      "   \"notes\": \"Thanks for your business.\",\n",
      "   \"terms_and_conditions\": \"All payments must be made in full before the commencement of any design work.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "json_string = output_text[0]\n",
    "\n",
    "json_string = json_string.strip(\"[]'\")\n",
    "json_string = json_string.replace(\"```json\\n\", \"\").replace(\"\\n```\", \"\")\n",
    "json_string = json_string.replace(\"'\", \"\")\n",
    "\n",
    "try:\n",
    "    formatted_json = json.loads(json_string)\n",
    "    print(json.dumps(formatted_json, indent=3))\n",
    "except json.JSONDecodeError as e:\n",
    "    print(\"Not valid JSON format:\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparando os resultados com a fatura (`invoice`) acima, notamos:\n",
    "\n",
    "* A saída do modelo é impecável — ele extrai todas as informações relevantes com precisão!\n",
    "\n",
    "* Isso ocorreu apesar da baixa qualidade da imagem e dos dados incorporados nas tabelas!\n",
    "\n",
    "* O `Qwen2-VL` menor teve um bom desempenho aqui, mas para imagens mais complexas ou texto manuscrito, você pode precisar de modelos maiores como `Qwen2-VL-7B`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=\"blue\">`Project 2:` Chat with Video</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O `Qwen2-VL` também pode extrair informações e interagir com vídeos.\n",
    "\n",
    "Para este projeto, usaremos um pequeno vídeo do `YouTube` — uma cena famosa de Pulp Fiction com a dança de John Travolta e Uma Thurman:\n",
    "\n",
    "\n",
    "Library for downloading youtube videos:\n",
    "```\n",
    "%pip install pytubefix\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/6MUy21DdnSc?controls=0&amp;showinfo=0\" frameborder=\"0\" allowfullscreen></iframe>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"orange\">Faça o download da seguinte forma:</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytubefix import YouTube\n",
    "from pytubefix.cli import on_progress\n",
    "\n",
    "file_name = \"youtube_short.mp4\"\n",
    "\n",
    "url = \"https://youtube.com/shorts/6MUy21DdnSc?si=-GofdpXBc97pTQ-E\"\n",
    "\n",
    "yt = YouTube(url, on_progress_callback = on_progress)\n",
    "print(yt.title)\n",
    "\n",
    "ys = yt.streams.get_highest_resolution()\n",
    "ys.download(filename=file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"youtube_short.mp4\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"orange\">Usaremos `Qwen2-VL-2B` novamente, pois consome menos recursos.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Qwen2VLForConditionalGeneration, AutoTokenizer, AutoProcessor\n",
    "from qwen_vl_utils import process_vision_info\n",
    "import json\n",
    "\n",
    "model_name = \"Qwen/Qwen2-VL-2B-Instruct\"\n",
    "\n",
    "model = Qwen2VLForConditionalGeneration.from_pretrained(\n",
    "     model_name,\n",
    "     torch_dtype=\"auto\",\n",
    "     ##attn_implementation=\"flash_attention_2\", #use flash-attention2 if your gpu card supports it (Free Colab's T4 does not support it)\n",
    "     device_map=\"cuda:0\", #\"auto\",\n",
    ")\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(\n",
    "    model_name\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos a função `chat_with_video`, que pega as `dimensões` do vídeo `redimensionado`, framess por segundo e a mensagem de texto que perguntaremos a `Qwen`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_with_video(file_name, query, video_width, video_height, fps=1.0):\n",
    "\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"video\",\n",
    "                    \"video\": file_name,\n",
    "                    \"max_pixels\": video_width * video_height,\n",
    "                    \"fps\": 1.0,\n",
    "                },\n",
    "                {\"type\": \"text\", \"text\": query},\n",
    "            ],\n",
    "        }\n",
    "    ]\n",
    "\n",
    "\n",
    "    text = processor.apply_chat_template(\n",
    "        messages, tokenize=False, add_generation_prompt=True\n",
    "    )\n",
    "\n",
    "\n",
    "    image_inputs, video_inputs = process_vision_info(messages)\n",
    "    inputs = processor(\n",
    "        text=[text],\n",
    "        images=image_inputs,\n",
    "        videos=video_inputs,\n",
    "        padding=True,\n",
    "        return_tensors=\"pt\",\n",
    "    )\n",
    "\n",
    "    inputs = inputs.to(\"cuda\")\n",
    "    #inputs = inputs.to(\"cpu\")\n",
    "\n",
    "\n",
    "    generated_ids = model.generate(**inputs, max_new_tokens=150)\n",
    "\n",
    "    generated_ids_trimmed = [\n",
    "        out_ids[len(in_ids) :] for in_ids, out_ids in zip(inputs.input_ids, generated_ids)\n",
    "    ]\n",
    "\n",
    "    output_text = processor.batch_decode(\n",
    "        generated_ids_trimmed, skip_special_tokens=True, clean_up_tokenization_spaces=False\n",
    "    )\n",
    "\n",
    "    return output_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"orange\">Vamos perguntar ao modelo:</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_text = chat_with_video(file_name, \"O que esse vídeo mostra?\", 360, 360)\n",
    "\n",
    "output_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"orange\">E outra pergunta:</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_text = chat_with_video(file_name, \"A mulher no vídeo está usando sapatos?\", 360, 420 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"orange\">Surpreendentemente, a modelo respondeu ambas as perguntas com precisão!\n",
    "\n",
    "`Algumas observações adicionais:`\n",
    "\n",
    "* Aumentar a altura, a largura e a taxa de frames (`fps`) do vídeo geralmente melhora a precisão, mas requer mais `GPU VRAM`.\n",
    "\n",
    "* O `Qwen2-VL` pode processar vídeos com mais de `20 minutos`, mas ainda `não processa som`.\n",
    "\n",
    "* Em meus experimentos, o `Qwen2-VL-7B` oferece o melhor equilíbrio entre precisão e requisitos de recursos (`GPU VRAM`).</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=\"blue\">`Project 3:` Multimodal RAG</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neste projeto, combinaremos o `Qwen2-VL` com outro modelo, `ColPali`, para executar `RAG` com `PDFs`.\n",
    "\n",
    "`ColPali` é um modelo de recuperação (retrieval) de documentos que contém um modelo `PaliGemma-3B` (também `VLM`) e um `Gemma-2B`. A função do `ColPali` é executar a parte de recuperação de documentos e criar um repositório de documentos multivetorial:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4434fdcd-312b-47fc-9d38-d8a5a5181902_985x593.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `Imagem superior:` Os sistemas de recuperação tradicionais usam ferramentas de `OCR` para extrair texto de imagens e, posteriormente, dividir o texto em `embeddings` de texto.\n",
    "\n",
    "* `Inferior: Imagem:` Em contraste, o `ColPali` executa `RAG` nos documentos visualmente (tratando a página do documento como uma imagem e dividindo-a em patches de imagem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O `pipeline` no nosso caso é o seguinte:\n",
    "\n",
    "* Converte cada página do `PDF` em uma imagem.\n",
    "\n",
    "* Insira as imagens no `ColPali` para armazenar uma representação `multivetorial` para cada página.\n",
    "\n",
    "* Envie uma consulta de texto ao `ColPali` para recuperar a(s) imagem(ns) relevante(s).\n",
    "\n",
    "* Envie a consulta de texto e as imagens relevantes para o `Qwen2-VL` para obter a resposta.\n",
    "\n",
    "\n",
    "\n",
    "Usaremos a biblioteca `Byaldi` para criar o `armazenamento de vetores de imagem`. O `Byaldi` carrega o `ColPali` (e modelos similares com a `API`). Também usaremos o `pdf2image` para converter o `PDF` em imagens.\n",
    "\n",
    "\n",
    "Vamos começar instalando as bibliotecas necessárias:\n",
    "\n",
    "\n",
    "```\n",
    "#pip install --upgrade byaldi\n",
    "\n",
    "pip install byaldi==0.0.5\n",
    "\n",
    "pip install -q git+https://github.com/huggingface/transformers.git qwen-vl-utils pdf2image\n",
    "\n",
    "\n",
    "\n",
    "## necessary tool for pdf2image\n",
    "\n",
    "!sudo apt-get install -y poppler-utils\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baixaremos um [PDF de 4 páginas](https://studyingreece.edu.gr/wp-content/uploads/2024/05/AUEB-International-Partnerships.pdf) para este projeto — um arquivo pequeno para conservar `VRAM`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "\n",
    "# We will use this pdf:\n",
    "url = \"https://studyingreece.edu.gr/wp-content/uploads/2024/05/AUEB-International-Partnerships.pdf\"\n",
    "\n",
    "# Download the file:\n",
    "pdf_filepath = url.split('/')[-1]\n",
    "\n",
    "urllib.request.urlretrieve(url, pdf_filepath)\n",
    "\n",
    "print(f\"Downloaded file name: {pdf_filepath}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_filepath = \"AUEB-International-Partnerships.pdf\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"orange\">`Como os modelos trabalham com imagens`, não com arquivos `PDF`, convertemos cada página em uma imagem. Se você quiser visualizar as imagens no `Jupyter/Colab`, execute este código:</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image as PILImage\n",
    "from pdf2image import convert_from_path\n",
    "from IPython.display import display\n",
    "\n",
    "images = convert_from_path(pdf_filepath)\n",
    "\n",
    "for page_number, page in enumerate(images):\n",
    "    resized_image = page.resize((600, 800), PILImage.Resampling.LANCZOS)\n",
    "\n",
    "    print(f\"Page {page_number + 1}:\")\n",
    "    display(resized_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"orange\">Em seguida, carregamos o `ColPali` e construímos nosso armazenamento de índice:</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from byaldi import RAGMultiModalModel\n",
    "\n",
    "RAG = RAGMultiModalModel.from_pretrained(\"vidore/colpali\")\n",
    "\n",
    "RAG.index(\n",
    "    input_path=pdf_filepath,\n",
    "    index_name=\"image_index\", # index will be saved at .byaldi/index_name/\n",
    "    store_collection_with_index=False,\n",
    "    overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"orange\">O índice contém `4` imagens — uma por página do `PDF`. Agora, carregamos `Qwen2-VL-2B`:</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Qwen2VLForConditionalGeneration, AutoTokenizer, AutoProcessor\n",
    "from qwen_vl_utils import process_vision_info\n",
    "import torch\n",
    "\n",
    "\n",
    "vlm_name = \"Qwen/Qwen2-VL-2B-Instruct\"\n",
    "model = Qwen2VLForConditionalGeneration.from_pretrained(vlm_name,\n",
    "                                                        torch_dtype=\"auto\", # \"auto\"\n",
    "                                                        device_map=\"cpu\") # \"auto\"\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(vlm_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A função `extract_answer_from_pdf` executa o seguinte:\n",
    "\n",
    "`1.` Dada uma text-query, pedimos a `Colpali` para recuperar a imagem mais relevante (`k=1`). A imagem representa uma página `PDF`.\n",
    "\n",
    "`2.` Dada uma text-query e a imagem relevante, pedimos ao `Qwen-VL-2B` para realizar o reconhecimento de imagem e fornecer uma resposta à nossa consulta de texto.\n",
    "\n",
    "`3.` A função retorna a resposta (`output_text`), o número da página que continha a resposta e a imagem/página relevante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_answer_from_pdf(text_query):\n",
    "\n",
    "  results = RAG.search(text_query, k=1)\n",
    "  print(results)\n",
    "\n",
    "  image_index = results[0][\"page_num\"] - 1\n",
    "  messages = [\n",
    "      {\n",
    "          \"role\": \"user\",\n",
    "          \"content\": [\n",
    "              {\n",
    "                  \"type\": \"image\",\n",
    "                  \"image\": images[image_index], ## contains the retrieved pdf page as image\n",
    "                  \"resized_height\": 527,\n",
    "                  \"resized_width\": 522,\n",
    "              },\n",
    "              {\"type\": \"text\", \"text\": text_query},\n",
    "          ],\n",
    "      }\n",
    "  ]\n",
    "\n",
    "  text = processor.apply_chat_template(\n",
    "    messages, tokenize=False, add_generation_prompt=True\n",
    "  )\n",
    "\n",
    "\n",
    "  image_inputs, video_inputs = process_vision_info(messages)\n",
    "  inputs = processor(\n",
    "      text=[text],\n",
    "      images=image_inputs,\n",
    "      videos=video_inputs,\n",
    "      padding=True,\n",
    "      return_tensors=\"pt\",\n",
    "  )\n",
    "  inputs = inputs.to(\"cpu\")\n",
    "\n",
    "  generated_ids = model.generate(**inputs, max_new_tokens=50)\n",
    "  ## remove the prompt from the answer\n",
    "  generated_ids_trimmed = [\n",
    "      out_ids[len(in_ids) :] for in_ids, out_ids in zip(inputs.input_ids, generated_ids)\n",
    "  ]\n",
    "  output_text = processor.batch_decode(\n",
    "      generated_ids_trimmed, skip_special_tokens=True, clean_up_tokenization_spaces=False\n",
    "  )\n",
    "\n",
    "  return output_text, results[0].page_num , images[image_index]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"orange\">Vamos perguntar ao nosso modelo:</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_query = \"Onde a AUEB está localizada?\" #\"Where AUEB is located?\"\n",
    "output_text, page_number, image =  extract_answer_from_pdf(text_query)\n",
    "\n",
    "print(\"\\n\\n\")\n",
    "print(output_text)\n",
    "print(f\"The answer is found in page {page_number} which is:\")\n",
    "display(image.resize((600, 800), PILImage.Resampling.LANCZOS))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb2348446-109f-428a-b57e-1c74cdedca5d_600x800.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O modelo está correto! `A Universidade AUEB fica em Atenas, Grécia.` Curiosamente, a resposta foi sintetizada de diferentes partes do texto (observe os quadrados verdes)\n",
    "\n",
    "Vamos fazer outra pergunta:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_query = \"Em que posição em Negócios e Gestão o programa foi classificado?\" #\"In which position in Business and Management did the program ranked?\"\n",
    "output_text, page_number, image =  extract_answer_from_pdf(text_query)\n",
    "\n",
    "print(\"\\n\\n\")\n",
    "print(output_text)\n",
    "print(f\"The answer is found in page {page_number} which is:\")\n",
    "display(image.resize((600, 800), PILImage.Resampling.LANCZOS))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2775280d-af6d-438e-8cf2-d1678fde60d4_600x800.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"orange\">O modelo está correto novamente, identificando a resposta no canto inferior direito da página 1.\n",
    "\n",
    "Vamos fazer uma última pergunta:</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_query = \"Qual é o endereço de e-mail e número de telefone de Thomas Bebis?\" #\"What is the email address and phone number of Thomas Bebis?\"\n",
    "output_text, page_number, image =  extract_answer_from_pdf(text_query)\n",
    "\n",
    "print(\"\\n\\n\")\n",
    "print(output_text)\n",
    "print(f\"The answer is found in page {page_number} which is:\")\n",
    "display(image.resize((600, 800), PILImage.Resampling.LANCZOS))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0c36d227-e9a5-48a9-b2c9-caaf92786d15_600x800.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Corrija novamente. Sinta-se à vontade para experimentar o modelo e fazer suas perguntas. `Você pode tentar idiomas diferentes também!`\n",
    "\n",
    "* `Podemos usar vários PDFs?`\n",
    "\n",
    "Sim! Basta colocar vários PDFs na pasta que `RAG.index()` acessa.\n",
    "\n",
    "* `Podemos recuperar mais de 1 imagem?`\n",
    "\n",
    "Sim. Neste caso, recuperamos apenas a imagem mais relevante (`k=1`). Você pode recuperar mais definindo `k=2` e, em seguida, passar ambas as imagens para o Qwen para processamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "javascript"
    }
   },
   "outputs": [],
   "source": [
    "chat_template = [\n",
    "  {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": [\n",
    "          {\n",
    "           \"type\": \"image\",\n",
    "           \"image\": image[0],\n",
    "          },\n",
    "          {\n",
    "            \"type\": \"image\",\n",
    "            \"image\": image[1],\n",
    "          },\n",
    "            {\"type\": \"text\", \"text\": text_query},\n",
    "      ],\n",
    "  }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`No entanto, adicionar mais PDFs ou recuperar várias páginas exige muito mais recursos.`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"gree\">Comentários finais + bônus (Llama-Vision3.2)</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este artigo explorou o `Qwen2-VL` para tarefas de `recuperação de imagens`, `vídeos` e `documentos`.\n",
    "\n",
    "Para casos mais complexos, você pode optar pelas versões maiores ou quantizadas do modelo — elas são reduzidas em tamanho com perda mínima de qualidade. Você pode encontrá-los [aqui](https://huggingface.co/collections/Qwen/qwen2-vl-66cee7455501d7126940800d).\n",
    "\n",
    "Outro caso de uso interessante para o `Qwen2-VL` é o `Fine_tuning` (que posso abordar em um artigo futuro).\n",
    "\n",
    "Além disso, há outros `VLMs` notáveis ​​como [Llama3.2-Vision](https://huggingface.co/meta-llama/Llama-3.2-11B-Vision) e [Aria](https://huggingface.co/rhymes-ai/Aria), incluindo uma versão quantizada do `Llama3.2-11B-Vision`. Se você estiver fora da UE (sim, os regulamentos da UE proíbem os modelos multimodais do Meta), você também pode executar meu `notebook` `Llama-Vision3.2`, que está disponível junto com os projetos Qwen."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_All",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
